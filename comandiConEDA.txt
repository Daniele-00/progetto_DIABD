Ecco un riepilogo dei comandi con i percorsi specifici basati sulla nostra conversazione. Esegui questi comandi dal terminale della tua VM Linux (come utente hadoop).

Ricorda: Devi sostituire <ID_ESECUZIONE> con l'ID effettivo stampato dal tuo script streaming_job.py (es. 32d7ee) e <NOME_FILE_PART_CSV> con il nome del file specifico che vuoi vedere (es. part-00000-....csv).

1. Copiare il contenuto della cartella locale VM (.../data/output/) a Windows (via cartella condivisa)

    Scopo: Copiare i risultati CSV (che erano stati precedentemente salvati o copiati in /home/hadoop/TrendSpotter-Cluster/data/output/) nella cartella condivisa /media/sf_shared accessibile da Windows.
    Comando:
    Bash

    cp -r /home/hadoop/TrendSpotter-Cluster/data/output/* /media/sf_shared/

    Note: Copia tutto il contenuto (*) della cartella output nella cartella /media/sf_shared/. Assicurati di avere i permessi di scrittura su /media/sf_shared/.

2. Copiare un'intera cartella di output streaming da HDFS alla VM Locale (es. nella home dir)

    Scopo: Scaricare l'intera cartella dei risultati di una specifica esecuzione dello streaming job da HDFS a una nuova cartella nella home directory della VM.
    Comando (sostituisci <ID_ESECUZIONE>):
    Bash

    hdfs dfs -get hdfs://master:9000/user/hadoop/trendspotter/output/live_topics_<ID_ESECUZIONE> /home/hadoop/output_hdfs_<ID_ESECUZIONE>

    Note: Questo creerà una nuova cartella locale chiamata output_hdfs_<ID_ESECUZIONE> nella tua home (/home/hadoop/) contenente tutti i file (_SUCCESS, part-*.csv, ecc.) da quella specifica esecuzione in HDFS.

3. Vedere l'elenco dei file in una cartella di output streaming su HDFS

    Scopo: Elencare i file (_SUCCESS, part-*.csv, .crc, ecc.) all'interno della cartella di output di una specifica esecuzione dello streaming job su HDFS.
    Comando (sostituisci <ID_ESECUZIONE>):
    Bash

    hdfs dfs -ls hdfs://master:9000/user/hadoop/trendspotter/output/live_topics_<ID_ESECUZIONE>/

    Note: Questo ti aiuta a vedere i nomi esatti dei file part-*.csv che potresti voler visualizzare o copiare singolarmente.

4. Vedere le prime righe (anteprima) di un file CSV specifico su HDFS

    Scopo: Visualizzare le prime 10 righe (o un numero diverso specificato con -n) di un particolare file part-*.csv direttamente da HDFS, senza scaricarlo completamente.
    Comando (sostituisci <ID_ESECUZIONE> e <NOME_FILE_PART_CSV>):
    Bash

hdfs dfs -cat hdfs://master:9000/user/hadoop/trendspotter/output/live_topics_<ID_ESECUZIONE>/<NOME_FILE_PART_CSV> | head -n 10

Note: Devi prima usare il comando ls (punto 3) per trovare il <NOME_FILE_PART_CSV> esatto che ti interessa. Puoi cambiare 10 in un altro numero se vuoi vedere più o meno righe.

// pulire file di checkpoint in neo4j
hdfs dfs -rm -r -skipTrash hdfs:///user/hadoop/spark_checkpoints/k5/neo4j_writer
hdfs dfs -rm -r -skipTrash hdfs:///user/hadoop/spark_checkpoints/k5/console_trends

-----------------------------------EDA--------------------------------------
"Durante l'analisi iniziale del dataset originale (News_Category_Dataset_v3), che contiene circa 220.000 record dal 2012 al 2022 e 
presenta 42 categorie distinte, sono emerse due considerazioni principali in relazione agli obiettivi del progetto TrendSpotter:

    Rilevanza Temporale: Poiché TrendSpotter mira a identificare trend emergenti e a simulare scenari in tempo reale 
    (simili a Twitter Trends o Google News), i dati più datati (2012-2019) sono stati considerati meno pertinenti per
     l'analisi dei trend attuali. Si è quindi deciso di filtrare il dataset mantenendo solo i record a partire dal 1 Gennaio 2020.
      Questa scelta focalizza l'analisi sui dati più recenti, allineandosi meglio agli obiettivi del progetto, e contemporaneamente 
      riduce la dimensione del dataset migliorando le prestazioni di elaborazione (clustering) e la leggibilità del grafo risultante.

    Granularità delle Categorie: L'elevato numero di categorie originali (42), che includeva anche sinonimi 
    (es. ARTS vs ARTS & CULTURE) e categorie molto specifiche, rischiava di frammentare eccessivamente l'analisi 
    e rendere difficile l'identificazione di macro-trend significativi. Per ottenere cluster più interpretabili e 
    un grafo più chiaro, si è scelto di raggruppare manualmente le 42 categorie originali in 22 categorie semantiche
     più coerenti (es. unendo BUSINESS e MONEY in BUSINESS_FINANCE, raggruppando diverse "Voices", ecc.). 
     Questo processo di consolidamento mira a migliorare la qualità del clustering basato sul contenuto testuale 
     (riducendo il "rumore" delle micro-categorie) e a semplificare la visualizzazione e l'interpretazione delle 
     relazioni tra argomenti e categorie nel grafo Neo4j, supportando direttamente gli obiettivi di identificazione
      e visualizzazione dei trend."




-----------------QUERY Utili per Esplorare il Grafo TrendSpotter in Neo4j

(Esegui queste query nel Neo4j Browser connesso al tuo database popolato)

MATCH (n) DETACH DELETE n

1. Panoramica Generale del Grafo

    Scopo: Capire la dimensione e la composizione di base del grafo.
    Query:
    Cypher

    // Query 1: Statistiche Generali del Grafo
    MATCH (n) RETURN labels(n) AS TipoNodo, count(*) AS Conteggio
    UNION ALL
    MATCH ()-[r]->() RETURN "Relazioni Totali" AS TipoNodo, count(r) AS Conteggio;

    Spiegazione: La prima parte conta quanti nodi ci sono per ogni etichetta (:Topic, :Category, :Cluster, :User). La seconda parte conta il numero totale di relazioni nel grafo. Utile per avere un'idea iniziale della scala.

2. Identificazione Trend Basata su Frequenza Cluster

    Scopo: Trovare i cluster (temi scoperti dall'algoritmo) che contengono il maggior numero di notizie, indicando i temi più frequenti nel periodo analizzato.
    Query:
    Cypher

    // Query 2: Cluster/Temi Più Frequenti (per dimensione)
    MATCH (c:Cluster)-[:CONTAINS]->(t:Topic)
    RETURN c.id AS ClusterID, count(t) AS NumeroNotizie
    ORDER BY NumeroNotizie DESC
    LIMIT 5; // Mostra i 5 cluster più grandi

    Spiegazione: Raggruppa per ID del cluster, conta i topic associati e ordina per mostrare i cluster più popolosi. Anche se i cluster non sono perfetti, quelli più grandi rappresentano aree dove l'algoritmo ha raggruppato più contenuto.

3. Identificazione Trend Basata su Frequenza Categorie (Raggruppate)

    Scopo: Trovare le categorie editoriali (quelle raggruppate manualmente) che contengono il maggior numero di notizie, indicando i temi generali più frequenti. Questo è spesso più interpretabile del solo ID del cluster.
    Query:
    Cypher

    // Query 3: Categorie Raggruppate Più Frequenti
    MATCH (cat:Category)<-[:BELONGS_TO]-(t:Topic)
    RETURN cat.name AS CategoriaRaggruppata, count(t) AS NumeroNotizie
    ORDER BY NumeroNotizie DESC
    LIMIT 5; // Mostra le 5 categorie più frequenti

    Spiegazione: Raggruppa per nome della categoria (raggruppata), conta i topic associati e ordina. Mostra quali aree tematiche generali sono più presenti.

4. Esplorazione Contenuto di un Cluster Specifico

    Scopo: Capire di cosa parla un cluster identificato come potenzialmente interessante (es. uno dei più frequenti dalla Query 2).
    Query (sostituisci 'ID_CLUSTER'):
    Cypher

    // Query 4: Esplora Contenuto Cluster (es. ID '3')
    MATCH (c:Cluster {id: '3'})-[:CONTAINS]->(t:Topic) // <-- Cambia '3' con l'ID che ti interessa
    RETURN t.name AS TitoloEsempio
    LIMIT 15; // Mostra fino a 15 titoli di esempio

    Spiegazione: Recupera i titoli (nomi dei nodi :Topic) appartenenti a un cluster specifico per una valutazione qualitativa del tema trattato.

5. Analisi Composizione di un Cluster per Categoria

    Scopo: Vedere quali categorie manuali (raggruppate) sono più presenti all'interno di un cluster specifico. Aiuta a interpretare il cluster.
    Query (sostituisci 'ID_CLUSTER'):
    Cypher

    // Query 5: Composizione Categorie in un Cluster (es. ID '3')
    MATCH (c:Cluster {id: '3'})-[:CONTAINS]->(t:Topic)-[:BELONGS_TO]->(cat:Category) // <-- Cambia '3'
    RETURN cat.name AS CategoriaRaggruppata, count(t) AS ConteggioNotizie
    ORDER BY ConteggioNotizie DESC;

    Spiegazione: Conta quanti topic di ciascuna categoria raggruppata appartengono a un dato cluster. Mostra quanto è "puro" o "misto" un cluster rispetto alle categorie manuali.

6. Dimostrazione Raccomandazione (Basata su Cluster)

    Scopo: Far vedere come il grafo abilita raccomandazioni "content-based" suggerendo topic da cluster simili a quelli che piacciono all'utente.
    Query (per utente 'Alessia'):
    Cypher

    // Query 6: Raccomandazione Basata su Cluster per 'Alessia'
    MATCH (u:User {name:'Alessia'})-[:INTERESTED_IN]->(liked_topic:Topic) // Topic che le piacciono
    MATCH (liked_topic)<-[:CONTAINS]-(c:Cluster)-[:CONTAINS]->(rec_topic:Topic) // Altri topic nello stesso cluster
    WHERE NOT (u)-[:INTERESTED_IN]->(rec_topic) // Che non le piacciono già
    RETURN DISTINCT rec_topic.name AS Raccomandazione, c.id AS DalCluster // Mostra raccomandazione e cluster di provenienza
    LIMIT 10;

    Spiegazione: Trova i cluster dei topic che piacciono ad Alessia e suggerisce altri topic dagli stessi cluster. (Nota: la qualità dipende dalla coerenza dei cluster!)

7. Dimostrazione Raccomandazione (Basata su Categoria Raggruppata)

    Scopo: Far vedere raccomandazioni "content-based" più robuste basate sulle categorie manuali raggruppate.
    Query (per utente 'Alessia'):
    Cypher

    // Query 7: Raccomandazione Basata su Categoria per 'Alessia'
    MATCH (u:User {name:'Alessia'})-[:INTERESTED_IN]->(liked_topic:Topic) // Topic che le piacciono
    MATCH (liked_topic)-[:BELONGS_TO]->(cat:Category) // Categoria di quei topic
    MATCH (rec_topic:Topic)-[:BELONGS_TO]->(cat) // Altri topic nella stessa categoria
    WHERE NOT (u)-[:INTERESTED_IN]->(rec_topic) // Che non le piacciono già
    RETURN DISTINCT rec_topic.name AS Raccomandazione, cat.name AS DallaCategoria // Mostra raccomandazione e categoria
    LIMIT 10;

    Spiegazione: Trova le categorie dei topic che piacciono ad Alessia e suggerisce altri topic dalle stesse categorie. (Questo probabilmente darà risultati più coerenti).

8. Trovare Utenti Interessati a un Tema/Cluster

    Scopo: Dimostrare come collegare i temi scoperti agli utenti.
    Query (per Cluster 'ID_CLUSTER'):
    Cypher

    // Query 8: Utenti Interessati a Topic nel Cluster (es. ID '3')
    MATCH (c:Cluster {id: '3'})-[:CONTAINS]->(t:Topic)<-[:INTERESTED_IN]-(u:User) // <-- Cambia '3'
    RETURN DISTINCT u.name AS UtenteInteressato, t.name AS TopicDiInteresse;

    Spiegazione: Trova quali utenti (tra quelli simulati) hanno mostrato interesse per i topic che appartengono a un cluster specifico.

Queste 8 query offrono una buona varietà per mostrare cosa puoi fare con il grafo che hai costruito. Spiegano come identificare temi frequenti (Query 2 e 3), come esplorarli (Query 4 e 5), come generare diversi tipi di raccomandazioni (Query 6 e 7) e come collegare gli utenti ai temi (Query 8). Puoi selezionare quelle che ritieni più significative da aggiungere al README o da mostrare durante una presentazione.


POSSIBILI DOMANDE-----------------
Introduzione per il Professore (Concetto Generale):
"Professore, il progetto TrendSpotter mira a costruire una pipeline Big Data end-to-end per l'identificazione e l'analisi di trend emergenti da flussi di notizie. L'obiettivo è stato dimostrare l'integrazione di tecnologie chiave come Kafka per l'ingestione, Spark (con Spark Streaming e MLlib) per l'elaborazione distribuita e l'analisi, Hadoop (HDFS/YARN) per lo storage e la gestione delle risorse, e Neo4j per la modellazione e visualizzazione di un grafo della conoscenza. Le scelte implementative sono state guidate dalla necessità di processare dati testuali, scoprire temi latenti, monitorare la loro attività nel tempo e abilitare potenziali raccomandazioni."

Area 1: Preprocessing e Gestione del Dataset

    Domanda Ipotetica: "Avete applicato un filtraggio temporale significativo (dati dal 2020 in poi, riducendo da ~220k a ~5.5k record) e un raggruppamento manuale delle categorie (da 42 a 22). Potete motivare queste scelte? Non si rischia di perdere informazioni o robustezza?"
        Giustificazione:
            Filtraggio Temporale (>= 2020):
                Rilevanza per "Trend Emergenti": L'obiettivo è identificare trend attuali. I dati storici (2012-2019) sono meno indicativi dei fenomeni correnti. La focalizzazione sul recente allinea il progetto agli scenari simulati (Google/Twitter Trends).
                Fattibilità e Performance: L'elaborazione dell'intero dataset, specialmente la generazione di Sentence Embeddings e il clustering su un cluster VM con risorse limitate, sarebbe stata proibitiva in termini di tempo. Il subset recente ha permesso di sviluppare e testare l'intera pipeline (incluso ML avanzato) in tempi ragionevoli.
                Gestibilità del Grafo: Un dataset mirato produce un grafo Neo4j più snello e interpretabile per la demo.
                Scalabilità Architetturale: L'architettura Spark/YARN è intrinsecamente scalabile; con più risorse, si potrebbero processare periodi più lunghi o l'intero dataset.
            Raggruppamento Categorie (da 42 a 22):
                Chiarezza e Riduzione Rumore: Le 42 categorie originali presentavano sovrapposizioni (es. ARTS, ARTS & CULTURE) e una granularità eccessiva. Questo poteva frammentare l'analisi e rendere difficile l'identificazione di macro-trend.
                Cluster Più Interpretabili: Un numero minore di categorie semantiche più coerenti aiuta il clustering a trovare gruppi tematici potenzialmente più distinti e facilita l'interpretazione del contenuto dei cluster.
                Grafo Semplificato: Meno nodi :Category e relazioni associate rendono il grafo Neo4j più leggibile.
                Processo: Il raggruppamento è stato fatto manualmente, basandosi sulla semantica delle categorie originali, per creare gruppi logici e significativi per il dominio delle notizie.

Area 2: Approccio al Clustering e Scelta dei Parametri

    Domanda Ipotetica: "Perché avete scelto il clustering per identificare i trend? E come siete arrivati alla pipeline finale con Sentence Embeddings, PCA e un certo numero K di cluster (es. K=5 o K=13, a seconda della vostra scelta finale)?"
        Giustificazione:
            Perché Clustering?: Per l'obiettivo di identificare argomenti/trend senza etichette predefinite per ogni possibile tema emergente, il clustering non supervisionato è un approccio standard. Permette di scoprire temi latenti basati sulla similarità del contenuto testuale.
            Evoluzione (da TF-IDF a Embeddings): Inizialmente è stato tentato un approccio classico con TF-IDF e KMeans, ma i risultati (bassi Silhouette Score) indicavano una scarsa separazione dei cluster, dovuta ai limiti di TF-IDF nel catturare la semantica profonda. Per superare questo, siamo passati ai Sentence Embeddings (con all-mpnet-base-v2), che forniscono una rappresentazione vettoriale molto più ricca del significato del testo.
            Pipeline di Preprocessing delle Feature: Agli embedding sono stati applicati StandardScaler (per normalizzare le feature) e PCA (per ridurre la dimensionalità a 40 componenti), tecniche standard per migliorare la performance di KMeans su vettori ad alta dimensione, riducendo il rumore e la complessità computazionale.
            Scelta di K (Numero di Cluster): Il numero finale di cluster K (es. 5 o 13, a seconda di quale ha dato i risultati migliori e più interpretabili nei vostri test finali) è stato determinato sperimentalmente. Abbiamo eseguito test con un range di valori di K, valutando sia il Silhouette Score (che con gli embedding e PCA è migliorato significativamente, es. ~0.135) sia, soprattutto, l'analisi qualitativa del contenuto dei cluster. Il K scelto rappresenta un compromesso tra una metrica quantitativa accettabile e la capacità di assegnare un tema coerente e interpretabile a ciascun cluster.
            Concetto di "Modello" KMeans: Anche se KMeans è non supervisionato, la fase di .fit() "addestra" il modello calcolando le posizioni ottimali dei centroidi dei cluster. Questo "modello" (i centroidi) viene poi salvato e riutilizzato per assegnare nuove notizie (dallo stream) ai cluster esistenti in modo consistente.

Area 3: Scelta delle Tecnologie dello Stack

    Domanda Ipotetica: "Potete giustificare la scelta di Neo4j rispetto ad altri database NoSQL? E chiarire il ruolo di Hadoop, YARN e Spark nel vostro progetto, inclusa la presenza concettuale di MapReduce?"
        Giustificazione:
            Neo4j (Graph Database):
                Centralità delle Relazioni: TrendSpotter si basa sulla comprensione delle connessioni tra notizie (Topic), temi (Cluster), categorie editoriali e utenti. Neo4j modella queste relazioni in modo nativo ed efficiente.
                Querying (Cypher): Cypher permette di interrogare queste relazioni complesse (es. per raccomandazioni, analisi di influenza) in modo intuitivo e performante, cosa difficile con altri NoSQL.
                Visualizzazione: Neo4j Browser è cruciale per l'esplorazione visiva dei trend e delle loro interconnessioni, un obiettivo chiave.
            Kafka: Usato per l'ingestione affidabile e scalabile di flussi di dati in tempo reale, disaccoppiando le fonti dall'elaborazione Spark.
            Hadoop HDFS: Fornisce lo storage distribuito e fault-tolerant per il dataset originale, per i modelli ML addestrati (Scaler, PCA, KMeans) e per i checkpoint di Spark Streaming, essenziali per la resilienza.
            Hadoop YARN: È il gestore delle risorse del cluster. Permette a Spark di operare in modo distribuito, allocando CPU e memoria sulle VM per l'esecuzione parallela dei task.
            Spark: È il motore di elaborazione distribuita per:
                Batch Processing (analyze_batch.py): Preprocessing dei dati storici, addestramento dei modelli ML (embedding, scaler, PCA, KMeans).
                Stream Processing (streaming_job.py): Elaborazione near real-time dei dati da Kafka, applicazione dei modelli ML pre-addestrati, aggiornamento diretto di Neo4j (tramite connettore), e analisi dei trend su finestre temporali.
            Concetto di MapReduce in Spark: Non abbiamo scritto codice MapReduce tradizionale. Tuttavia, Spark, per eseguire le operazioni distribuite sui DataFrame (come groupBy, count, UDF su partizioni, addestramento ML), internamente scompone il lavoro in stadi e task che seguono i principi di Map (applicare una funzione a molti dati in parallelo) e Reduce (aggregare risultati), spesso con fasi di Shuffle gestite efficientemente da Spark su YARN. Il servizio mapreduce_shuffle in YARN supporta queste operazioni.

Area 4: Architettura del Cluster e Distribuzione del Lavoro

    Domanda Ipotetica: "Avete 3 VM. Come verificate che il lavoro Spark sia effettivamente distribuito? Perché a volte i job potrebbero non usare tutti i nodi worker disponibili?"
        Giustificazione:
            Verifica Distribuzione: Utilizziamo la YARN UI (http://master:8088) per vedere l'allocazione dei container Spark sugli host (master, worker1, worker2) e la Spark UI (http://master:4040) per monitorare gli executor attivi, i task in esecuzione e la loro distribuzione sui nodi. La tab "Stages" della Spark UI mostra come un'operazione (es. generazione embedding) venga divisa in numerosi task paralleli eseguiti su più executor.
            Perché Non Sempre Tutti i Nodi?:
                Quantità di Lavoro: Se il numero di partizioni dei dati o di task in uno stadio è piccolo, Spark potrebbe non aver bisogno di utilizzare tutti i core di tutti gli executor disponibili.
                Allocazione Dinamica: Se attiva, Spark può rilasciare executor inattivi.
                Disponibilità Risorse YARN: YARN alloca container in base alla disponibilità momentanea sui nodi.
                Località Dati: Spark preferisce eseguire task sui nodi dove i dati HDFS risiedono.
                Questo è un comportamento normale: Spark e YARN cercano di usare le risorse in modo efficiente, non necessariamente di saturare sempre tutti i nodi se non è richiesto dal carico.

Area 5: Funzionalità "TrendSpotter" (Come Vengono Identificati i Trend)

    Domanda Ipotetica: "Come identificate specificamente un trend 'emergente' e non solo un argomento frequente?"
        Giustificazione:
            Base: I cluster K=5 [o K=13] identificati rappresentano i temi principali nei dati recenti (post-2020).
            Identificazione Frequenza (Batch): La dimensione di questi cluster nel job batch indica la dominanza di un tema in quel periodo.
            Monitoraggio Emergenza (Streaming): L'aspetto "emergente" è indirizzato dallo streaming_job.py tramite l'analisi dei conteggi dei cluster su finestre temporali (tumbling windows), i cui risultati vengono stampati sulla console. Osservando la variazione della frequenza (colonna count) di un ClusterID specifico attraverso le finestre temporali successive, possiamo identificare un tema la cui attività sta aumentando significativamente o che mostra picchi improvvisi. Questo aumento di attività nel tempo è il nostro indicatore di trend emergente. L'analisi qualitativa del contenuto del cluster (tramite Neo4j) ne chiarisce poi il significato.

